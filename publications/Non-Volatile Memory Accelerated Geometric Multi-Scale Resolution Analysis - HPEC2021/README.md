# mcas-gmra
# Abstract
mensionality reduction algorithms are standard
tools in a researcherâ€™s toolbox. Dimensionality reduction algorithms
are frequently used to augment downstream tasks such
as machine learning, data science, and also are exploratory
methods for understanding complex phenomena. For instance,
dimensionality reduction is commonly used in Biology as well
as Neuroscience to understand data collected from biological
subjects. However, dimensionality reduction techniques are limited
by the von-Neumann architectures that they execute on.
Specifically, data intensive algorithms such as dimensionality
reduction techniques often require fast, high capacity, persistent
memory which historically hardware has been unable to provide
at the same time. In this paper, we present a re-implementation
of an existing dimensionality reduction technique called Geometric
Multi-Scale Resolution Analysis (GMRA) which has
been accelerated via novel persistent memory technology called
Memory Centric Active Storage (MCAS). Our implementation
uses a specialized version of MCAS called PyMM that provides
native support for Python datatypes including NumPy arrays
and PyTorch tensors. We compare our PyMM implementation
against a DRAM implementation, and show that when data fits in
DRAM, PyMM offers competitive runtimes. When data does not
fit in DRAM, our PyMM implementation is still able to process
the data.

Link for the paper: 


# Dependencies
1) tensorflow (doesn't matter cpu or gpu version...using it to load mnist)
2) pytorch
3) sklearn
4) tqdm (python package)
5) cmake (> 3.0)
6) mcas (and pymm)

## NOTE
-mcas installs to your system python interpreter. Therefore, the rest of these dependencies must be installed to the system interpreter as well (will still work if installed to the user (--user) system environment).

-Special note about pytorch. If you have a prebuilt binary, then you *must* have the cuda/cudnn/nccl versions that the prebuilt version is expecting. Normally this isn't a problem when using pytorch, however this will cause the libtorch cmake toolchain to error and the build to fail.

-I am currently testing whether building pytorch from source fixes this problem, so standby.

## UPDATE
if you are getting an error from the pytorch cmake toolchain about not being able to find cuda/cudnn/nccl, you need to either install the expected libraries (and add them to your LD_LIBRARY_PATH, etc.) OR you can compile pytorch from source. The cmake toolchain is autogenerated and will NOT have gpu dependencies for a cpu only build!


# Building
there are git submodules so be sure to run:

```git submodule update --init --recursive```

Then, cd to the pymm-gmra directory. The code can be build using
```python3 setup.py build```

and then installed using
```python3 setup.py install --user```

Running the install command will also build the code (if unbuilt or modified).


Finally, if you cd into the examples directory, you will see examples of running the code on mnist. I recommend trying

mnist_nopymm_cpp.py if you do *not* have pymm installed, otherwise mnist_pymm_cpp.py

The *_cpp.py scripts will use the c++ data structures instead of the pure python versions (which the other scripts will use). Warning: pure python scripts are very, very, slow.

